{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizagem Supervisionada\n",
    "## Projeto 2: Construindo um Sistema de Intervenção para Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem-vindo ao segundo projeto do Nanodegree de Machine Learning! Neste Notebook, alguns templates de código já foram fornecidos, e será o seu trabalho implementar funcionalidades necessárias para completar este projeto com êxito. Seções que começam com **'Implementação'** no cabeçalho indicam que o bloco de código que se segue precisará de funcionalidades adicionais que você deve fornecer. Instruções serão providenciadas para cada seção e as especificações para cada implementação estarão marcadas no bloco de código com o comando `'TODO'`. Tenha certeza de ler atentamente todas as instruções!\n",
    "\n",
    "Além do código implementado, haverá questões relacionadas ao projeto e à implementação que você deve responder. Cada seção em que você tem que responder uma questão será antecedida de um cabeçalho **'Questão X'**. Leia atentamente cada questão e escreva respostas completas nas caixas de texto subsequentes que começam com **'Resposta: '**. O projeto enviado será avaliado baseado nas respostas para cada questão e a implementação que você forneceu.  \n",
    "\n",
    ">**Nota:** Células de código e Markdown podem ser executadas utilizando o atalho de teclado **Shift + Enter**. Além disso, as células Markdown podem ser editadas, um clique duplo na célula entra no modo de edição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Classificação versus Regressão\n",
    "*Seu objetivo neste projeto é identificar estudantes que possam precisar de intervenção antecipada antes de serem reprovados. Que tipo de problema de aprendizagem supervisionada é esse: classificação ou regressão? Por quê?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Se baseando somente na pergunta, creio que esse é um problema de classificação binária visto que devo atingir tal objetivo criando um classificador que dado as variáveis de um determinado estudante irá classificar o mesmo como alguém que precisa ou não de intervenção. Por isso, seria um classificador binário, já que temos apenas duas classes (Intervir ou Não intervir).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os Dados\n",
    "Execute a célula de código abaixo para carregar as bibliotecas de Python necessárias e os dados sobre os estudantes. Note que a última coluna desse conjunto de dados, `'passed'`, será nosso rótulo alvo (se o aluno foi ou não aprovado). As outras colunas são atributos sobre cada aluno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados dos estudantes foram lidos com êxito!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Ler os dados dos estudantes\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Os dados dos estudantes foram lidos com êxito!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Observando os Dados\n",
    "Vamos começar observando o conjunto de dados para determinar quantos são os estudantes sobre os quais temos informações e entender a taxa de graduação entre esses estudantes. Na célula de código abaixo, você vai precisar calcular o seguinte:\n",
    "- O número total de estudantes, `n_students`.\n",
    "- O número total de atributos para cada estudante, `n_features`.\n",
    "- O número de estudantes aprovados, `n_passed`.\n",
    "- O número de estudantes reprovados, `n_failed`.\n",
    "- A taxa de graduação da classe, `grad_rate`, em porcentagem (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de estudantes: 395\n",
      "Número de atributos: 30\n",
      "Número de estudantes aprovados: 265\n",
      "Número de estudantes reprovados: 130\n",
      "Taxa de graduação: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calcule o número de estudante\n",
    "n_students = student_data.shape[0]\n",
    "\n",
    "# TODO: Calcule o número de atributos\n",
    "n_features = student_data.shape[1] - 1\n",
    "\n",
    "# TODO: Calcule o número de alunos aprovados\n",
    "n_passed = len(student_data[student_data['passed'] == 'yes'])\n",
    "\n",
    "# TODO: Calcule o número de alunos reprovados\n",
    "n_failed = len(student_data[student_data['passed'] == 'no'])\n",
    "\n",
    "# TODO: Calcule a taxa de graduação\n",
    "grad_rate = (n_passed/float(n_students))*100\n",
    "\n",
    "# Imprima os resultados\n",
    "print \"Número total de estudantes: {}\".format(n_students)\n",
    "print \"Número de atributos: {}\".format(n_features)\n",
    "print \"Número de estudantes aprovados: {}\".format(n_passed)\n",
    "print \"Número de estudantes reprovados: {}\".format(n_failed)\n",
    "print \"Taxa de graduação: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados\n",
    "Nesta seção, vamos preparara os dados para modelagem, treinamento e teste.\n",
    "\n",
    "### Identificar atributos e variáveis-alvo\n",
    "É comum que os dados que você obteve contenham atributos não numéricos. Isso pode ser um problema, dado que a maioria dos algoritmos de machine learning esperam dados númericos para operar cálculos.\n",
    "\n",
    "Execute a célula de código abaixo para separar os dados dos estudantes em atributos e variáveis-alvo e verificar se algum desses atributos é não numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de atributos:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Coluna-alvo: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraia as colunas dos atributo\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extraia a coluna-alvo 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print \"Colunas de atributos:\\n{}\".format(feature_cols)\n",
    "print \"\\nColuna-alvo: {}\".format(target_col)\n",
    "\n",
    "# Separe os dados em atributos e variáveis-alvo (X_all e y_all, respectivamente)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Mostre os atributos imprimindo as cinco primeiras linhas\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processar Colunas de Atributo\n",
    "\n",
    "Como você pode ver, há muitas colunas não numéricas que precisam ser convertidas! Muitas delas são simplesmente `yes`/`no`, por exemplo, a coluna `internet`. É razoável converter essas variáveis em valores (binários) `1`/`0`.\n",
    "\n",
    "Outras colunas, como `Mjob` e `Fjob`, têm mais do que dois valores e são conhecidas como variáveis categóricas. A maneira recomendada de lidar com esse tipo de coluna é criar uma quantidade de colunas proporcional aos possíveis valores (por exemplo, `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc), e assinalar `1` para um deles e `0` para todos os outros.\n",
    "\n",
    "Essas colunas geradas são por vezes chamadas de _variáveis postiças_ (_dummy variables_), e nós iremos utilizar a função [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para fazer essa conversão. Execute a célula de código abaixo para executar a rotina de pré-processamento discutida nesta seção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Pré-processa os dados dos estudantes e converte as variáveis binárias não numéricas em\n",
    "        variáveis binárias (0/1). Converte variáveis categóricas em variáveis postiças. '''\n",
    "    \n",
    "    # Inicialize nova saída DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Observe os dados em cada coluna de atributos \n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # Se o tipo de dado for não numérico, substitua todos os valores yes/no por 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Se o tipo de dado for categórico, converta-o para uma variável dummy\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Reúna as colunas revisadas\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Divisão dos Dados de Treinamento e Teste\n",
    "Até agora, nós convertemos todos os atributos _categóricos_ em valores numéricos. Para o próximo passo, vamos dividir os dados (tanto atributos como os rótulos correspondentes) em conjuntos de treinamento e teste. Na célula de código abaixo, você irá precisar implementar o seguinte:\n",
    "- Embaralhe aleatoriamente os dados (`X_all`, `y_all`) em subconjuntos de treinamento e teste.\n",
    "  - Utilizar 300 pontos de treinamento (aproxidamente 75%) e 95 pontos de teste (aproximadamente 25%).\n",
    "  - Estabelecer um `random_state` para as funções que você utiliza, se a opção existir.\n",
    "  - Armazene os resultados em `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 300 amostras.\n",
      "O conjunto de teste tem 95 amostras.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe qualquer funcionalidade adicional de que você possa precisar aqui\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# TODO: Estabeleça o número de pontos de treinamento\n",
    "num_train = 300\n",
    "\n",
    "# Estabeleça o número de pontos de teste\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test/float(X_all.shape[0]), random_state=11)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print \"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0])\n",
    "print \"O conjunto de teste tem {} amostras.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando Modelos\n",
    "Nesta seção, você irá escolher 3 modelos de aprendizagem supervisionada que sejam apropriados para esse problema e que estejam disponíveis no `scikit-learn`. Primeiro você irá discutir o raciocínio por trás da escolha desses três modelos considerando suas vantagens e desvantagens e o que você sabe sobre os dados. Depois você irá ajustar o modelo a diferentes tamanhos de conjuntos de treinamento (com 100, 200 e 300 pontos) e medir a pontuação F<sub>1</sub>. Você vai precisar preencher três tabelas (uma para cada modelo) que mostrem o tamanho do conjunto de treinamento, o tempo de treinamento, o tempo de previsão e a pontuação F<sub>1</sub> no conjunto de treinamento.\n",
    "\n",
    "**Os seguintes modelos de aprendizagem supervisionada estão atualmente disponíveis no **[`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)** para você escolher:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Árvores de Decisão\n",
    "- Métodos de agregação (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Método do gradiente estocástico (SGDC)\n",
    "- Máquinas de vetores de suporte (SVM)\n",
    "- Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação dos Modelos\n",
    "*Liste três modelos de aprendizagem supervisionada que são apropriadas para esse problema. Para cada modelo escolhido:*\n",
    "- Descreva uma aplicação em mundo real na indústria em que o modelo pode ser aplicado. *(Talvez você precise fazer um pouco de pesquisa para responder essa questão – dê as devidas referências!)* \n",
    "- Quais são as vantagens do modelo; quando ele tem desempenho melhor? \n",
    "- Quais são as desvantagens do modelo, quando ele tem desempenho pior?\n",
    "- O que faz desse modelo um bom candidato para o problema, considerando o que você sabe sobre os dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "\n",
    "1. __Decision Tree__: Esse é um modelo muito bom para tomada de decisão, visto que o mesmo é, basicamente, um compilado de diversas condições lógicas (If...Then..Else) que encadeadas ajudam o usuário a solucionar seu problema. \n",
    "    * __Aplicação__: Imagine que temos dados de pacientes de um hospital e queremos priorizar o atendimento aos indivíduos mais necessitados. Podemos fazer isso usando atributos como idade, pressão sanguínea, peso, doênças na familia, etc.   \n",
    "    * __Vantagens__: - É um modelo de fácil explicação, mesmo para um leigo, já que ao fim do treinamento poderemos observar a árvore construída e interpretar todos os caminhos da mesma. Além do mais, consegue lidar com variáveis categóricas e numéricas. Ambos os tipos se encontram presentes no nossos dados.\n",
    "    * __Desvantagens__: É um modelo que pode se tornar instável devido a pequenas variações nos dados resultando em uma árvore completamente diferente da ideal. Ademais, a árvore pode ficar enviesada a predizer uma classe em detrimento de outra, caso tenhamos um dataset muito desbalanceado.  \n",
    "    * __Por que é um bom modelo pra esse problema?__ O nosso objetivo é identificar se o aluno precisa ou não de itervenção e, acredito que justificar o porquê dessa decisão para os diretores da escola também seja importante. Usando uma decision tree, será mais fácil justificar nossa decisão, visto que para isso basta percorrer o caminho da árvore que levou o modelo a sua conclusão. Além disso, acredito que as variáveis do dataset apresentem alguma construção lógica que tenha relação com a classificação e sabendo que o objetivo desse modelo é encontrar tais construções, então penso que o mesmo seja um bom candidato. E como nosso dataset não apresenta um desbalanceamento de classes significativo, então isso diminui as chances da árvore se tornar enviesada para uma classe.\n",
    "    \n",
    "2. __KNN__: Esse é um dos modelos de machine learning mais simples e intuitivo de se entender, pois ele se baseia na ideia de classificar cada  ponto dos dados usando a classificação dos pontos mais próximos. O que é conhecido como __aprendizado baseado em instâncias__.\n",
    "    * __Aplicação__: É um algoritmo que pode ser usado para predizer o preço de um imóvel baseado nos preços dos imóveis que se encontram geograficamente próximos ao mesmo.\n",
    "    * __Vantagens__: O tempo de treinamento é constante, visto que não precisamos contruir um modelo propriamente dito. Os nossos dados são o modelo em si. Tal característica é conhecida como __aprendizagem preguiçosa__.\n",
    "    * __Desvantagens__: Precisamos de memória suficiente para armazenar os dados, pois toda classificação feita é baseado nos mesmos. No nosso caso, isso não é problema, pois estamos lidando com um dataset pequeno.\n",
    "    * __Por que é um bom modelo pra esse problema?__ _KNN_ é um algoritmo de aprendizado baseado em instâncias. Em outras palvras, ele procura os dados mais próximos/similares aquele ponto para classificá-lo. Pensando dessa forma, acredito que ele é um bom modelo pra essa situação, pois penso que os dois conjuntos de alunos (Precisam de intervenção e não precisam) apresentam um determinado padrão de características próprias. Ou seja, os alunos que precisam de intervenção são similares/próximos uns aos outros. O mesmo deve ocorrer com os que não precisam. Dessa forma, podemos usar a premissa do _KNN_ a fim de classificar um aluno comparando com os alunos de cada um dos conjuntos e verificar quais são aqueles que são mais similares ou estão mais próximos a ele. Além do mais, podemos seguir o  [fluxograma](http://scikit-learn.org/stable/_static/ml_map.png) disponibilizado pelo scikit-learn e verificar que as caracteristicas desse problema (Classes conhecidas, dados classificados e menos de 100 mil linhas de dados) podem nos levar ao _KNN_.\n",
    "    \n",
    "3. __Support Vector Machines__: Esse é um modelo um pouco mais complexo do que os anteriores. Esse algoritmo procura encontrar o melhor hiperplano que discrimina os dados.\n",
    "    * __Aplicação__: Pode ser aplicado pra classificar partes de uma imagem como sendo de uma face ou não. No caso, poderia ter como base de treinamento um vetor de características de cada pixel de uma imagem, no qual cada pixel seria classificado como sendo uma parte da face ou não. \n",
    "    * __Vantagens__: Sabe lidar bem com uma grande quantidade de atributos, até mesmo em casos em que a quantidade dos mesmos é maior que a quantidade de dados. \n",
    "    * __Desvantagens__: Não prover diretamente uma estimação de probabilidades para as classes. Tal probabilidade pode ser interpretada como quão certo o modelo está sobre a classificação retornada. Alguns modelos não apresentam tal probabilidade. O _SVM_ é um deles, porém existe algumas formas de contornar isso. A biblioteca do scikit-learn, por exemplo, o faz usando um método conhecido como _[Platt scaling](https://en.wikipedia.org/wiki/Platt_scaling)_ que, basicamente, usa regressão logistica aplicada ao resultado do classificador a fim de retornar o grau de certeza da classificação. Contudo, tal método não é sempre eficiente e pode ser muito custoso quando aplicado em datasets grandes como é ressaltado nesta [seção](http://scikit-learn.org/stable/modules/svm.html#scores-and-probabilities) da documentação do scikit-learn.\n",
    "    * __Por que é um bom modelo pra esse problema?__ Temos um dataset com uma grande quantidade de atributos (Trinta no total) e com uma variável-alvo binária. Sabemos que uma das vantagens do _SVM_ é apresentar uma boa performance nesse tipo de cenário, por isso acredito que ele deve ser um bom candidato. A fim de melhor embasar minha escolha, novamente usei o [fluxograma](http://scikit-learn.org/stable/_static/ml_map.png) e pude constatar que o _SVM_ é um dos modelos que se encontra no caminho de caracteristicas desse problema (Classes conhecidas, dados classificados e menos de 100 mil linhas de dados).\n",
    "    \n",
    "Fontes:\n",
    "* [Scikit ML map](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "\n",
    "\n",
    "* [SVM Scikit API](http://scikit-learn.org/stable/modules/svm.html#svm)\n",
    "* [KNN Scikit API](http://scikit-learn.org/stable/modules/neighbors.html)\n",
    "* [Decision Tree Scikit API](http://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "\n",
    "* [Decision Tree application](https://pdfs.semanticscholar.org/52a5/c35d9ade36348d8688f20d1de3d9d1cde77c.pdf)\n",
    "* [SVM application](https://data-flair.training/blogs/applications-of-svm/) - Primeiro exemplo.\n",
    "* [KNN application](https://github.com/soutik/Boston-Housing-dataset-exploration-with-KNN/blob/master/Boston-Housing-KNN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n",
    "Execute a célula de código abaixo para inicializar três funções de ajuda que você pode utilizar para treinar e testar os três modelos de aprendizagem supervisionada que você escolheu acima. As funções são as seguintes:\n",
    "- `train_classifier` - recebe como parâmetro um classificador e dados de treinamento e ajusta o classificador aos dados.\n",
    "- `predict_labels` - recebe como parâmetro um classificador ajustado, atributos e rótulo alvo e faz estimativas utilizando a pontuação do F<sub>1</sub>.\n",
    "- `train_predict` - recebe como entrada um classificador, e dados de treinamento e teste, e executa `train_clasifier` e `predict_labels`.\n",
    " - Essa função vai dar a pontuação F<sub>1</sub> tanto para os dados de treinamento como para os de teste, separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print \"O modelo foi treinado em {:.4f} segundos\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    print \"As previsões foram feitas em {:.4f} segundos.\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    print \"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Treina o classificador\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    print \"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Métricas de Desempenho do Modelo\n",
    "Com as funções acima, você vai importar os três modelos de aprendizagem supervisionada de sua escolha e executar a função `train_prediction` para cada um deles. Lembre-se de que você vai precisar treinar e usar cada classificador para três diferentes tamanhos de conjuntos de treinamentos: 100, 200 e 300 pontos. Então você deve ter 9 saídas diferentes abaixo – 3 para cada modelo utilizando cada tamanho de conjunto de treinamento. Na célula de código a seguir, você deve implementar o seguinte:\n",
    "- Importe os três modelos de aprendizagem supervisionada que você escolheu na seção anterior.\n",
    "- Inicialize os três modelos e armazene eles em `clf_A`, `clf_B` e `clf_C`.\n",
    " - Defina um `random_state` para cada modelo, se a opção existir.\n",
    " - **Nota:** Utilize as configurações padrão para cada modelo – você vai calibrar um modelo específico em uma seção posterior.\n",
    "- Crie diferentes tamanhos de conjuntos de treinamento para treinar cada modelo.\n",
    " - *Não embaralhe e distribua novamente os dados! Os novos pontos de treinamento devem ser tirados de `X_train` e `y_train`.*\n",
    "- Treine cada modelo com cada tamanho de conjunto de treinamento e faça estimativas com o conjunto de teste (9 vezes no total).  \n",
    "**Nota:** Três tabelas são fornecidas depois da célula de código a seguir, nas quais você deve anotar seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando um SVC com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0024 segundos\n",
      "As previsões foram feitas em 0.0014 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8684.\n",
      "As previsões foram feitas em 0.0011 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7945.\n",
      "\n",
      "Treinando um SVC com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0054 segundos\n",
      "As previsões foram feitas em 0.0039 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8758.\n",
      "As previsões foram feitas em 0.0020 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8235.\n",
      "\n",
      "Treinando um SVC com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0114 segundos\n",
      "As previsões foram feitas em 0.0085 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8596.\n",
      "As previsões foram feitas em 0.0028 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8344.\n",
      "#########################\n",
      "Treinando um KNeighborsClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0009 segundos\n",
      "As previsões foram feitas em 0.0034 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8322.\n",
      "As previsões foram feitas em 0.0016 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8028.\n",
      "\n",
      "Treinando um KNeighborsClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0009 segundos\n",
      "As previsões foram feitas em 0.0042 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8718.\n",
      "As previsões foram feitas em 0.0024 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7972.\n",
      "\n",
      "Treinando um KNeighborsClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0011 segundos\n",
      "As previsões foram feitas em 0.0092 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8623.\n",
      "As previsões foram feitas em 0.0033 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8148.\n",
      "#########################\n",
      "Treinando um DecisionTreeClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0012 segundos\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0002 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7077.\n",
      "\n",
      "Treinando um DecisionTreeClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0019 segundos\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6504.\n",
      "\n",
      "Treinando um DecisionTreeClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0029 segundos\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7460.\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe os três modelos de aprendizagem supervisionada do sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = svm.SVC(random_state=10)\n",
    "clf_B = KNeighborsClassifier()\n",
    "clf_C = tree.DecisionTreeClassifier(random_state=10)\n",
    "\n",
    "# TODO: Configure os tamanho dos conjuntos de treinamento\n",
    "X_train_100 = X_train[:100]\n",
    "y_train_100 = y_train[:100]\n",
    "\n",
    "X_train_200 = X_train[:200]\n",
    "y_train_200 = y_train[:200]\n",
    "\n",
    "X_train_300 = X_train[:300]\n",
    "y_train_300 = y_train[:300]\n",
    "\n",
    "# TODO: Executar a função 'train_predict' para cada classificador e cada tamanho de conjunto de treinamento\n",
    "# train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    train_predict(clf, X_train_100, y_train_100, X_test, y_test)\n",
    "    print\n",
    "    train_predict(clf, X_train_200, y_train_200, X_test, y_test)\n",
    "    print \n",
    "    train_predict(clf, X_train_300, y_train_300, X_test, y_test)\n",
    "    print \"#########################\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados em tabelas\n",
    "Edite a célula abaixo e veja como a tabela pode ser desenhada em [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables). Você deve salvar seus resultados abaixo nas tabelas fornecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classificador 1 - SVM**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |         0.0024       |  0.0011                    |    0.8684                  |  0.7945                     |\n",
    "| 200                                |       0.0054         |      0.0020                 |           0.8758           | 0.8235                    |\n",
    "| 300                                |        0.0114        |             0.0028          |           0.8596           | 0.8344      \n",
    "\n",
    "\n",
    "** Classificador 2 - KNN**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |   0.0009             |    0.0016                   |  0.8322                   | 0.8028                     |\n",
    "| 200                                |      0.0009        |  0.0024                     |  0.8718                    | 0.7972                    |\n",
    "| 300                                |       0.0011        |  0.0033                    |   0.8623                   |        0.8148       |\n",
    "\n",
    "** Classificador 3 - Decision Tree**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |0.0012                | 0.0002                      | 1.0000                    | 0.7077                     |\n",
    "| 200                                |0.0019                | 0.0003                      |  1.0000                    |0.6504                     |\n",
    "| 300                                |0.0029                | 0.0003                      | 1.0000                     | 0.7460                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o Melhor Modelo\n",
    "Nesta seção final, você irá escolher dos três modelos de aprendizagem supervisionada o *melhor* para utilizar os dados dos estudantes. Você então executará um busca em matriz otimizada para o modelo em todo o conjunto de treinamento (`X_train` e `y_train`) ao calibrar pelo menos um parâmetro, melhorando em comparação a pontuação F<sub>1</sub> do modelo não calibrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o Melhor Modelo\n",
    "*Baseando-se nos experimentos que você executou até agora, explique em um ou dois parágrafos ao conselho de supervisores qual modelo que você escolheu como o melhor. Qual modelo é o mais apropriado baseado nos dados disponíveis, recursos limitados, custo e desempenho?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Após avaliar a tabela com os resultados, o modelo escolhido é o __SVM__, pois, apesar do mesmo apresentar um tempo de treinamento superior comparado aos outros modelos, ele tem um F1 nos dados de teste superior aos outros dois modelos. Além disso, observando os resultados, vemos que o modelo de __decision tree__ sofreu overvitting (F1 igual à 1 no treinamento) e, por isso, não consegue generalizar bem (F1 baixo nos dados de testes), ao passo que o __knn__, apresentou uma performance quase tão boa quanto o __SVM__, obtendo uma média de F1 nos testes de __0.8049__. Contudo, __SVM__ foi um pouco superior, obtendo uma média de F1 nos testes de __0.8174__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 – O Modelo para um Leigo\n",
    "*Em um ou dois parágrafos, explique para o conselho de supervisores, utilizando termos leigos, como o modelo final escolhido deve trabalhar. Tenha certeza que você esteja descrevendo as melhores qualidades do modelo, por exemplo, como o modelo é treinado e como ele faz uma estimativa. Evite jargões técnicos ou matemáticos, como descrever equações ou discutir a implementação do algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Todo o processo de decidir qual o melhor modelo a ser aplicado começa sempre com a divisão dos dados em __treino__ e __teste__, onde usamos o treino para construir o modelo e o teste para avaliá-lo. A ideia aqui é que o modelo aprenda a melhor forma de classificar os alunos a partir de exemplos que já se encontram classificados. Uma vez que o modelo tenha passado por essa fase de __treinamento__, podemos aplicá-lo nos dados de teste e avaliar sua performance comparando a classificação sugerida pelo modelo e a classificação real (**Fase de teste**). Existe diversas métricas para mensurar a performance do modelo. Nesse caso, nós estamos considerando uma métrica de avaliação conhecida como __F-Measure__. Quanto maior o valor da mesma, melhor nosso modelo, e maiores são as chances do mesmo acertar se um determinado aluno precisa ou não de intervenção. Com isso em mente e observando a coluna de pontuação nos dados de teste, vemos que o modelo __SVM__ é o que apresentou um melhor desempenho. Além disso, é importante notar, também, que ele teve um tempo de treinamento significamente superior aos outros, porém como estamos lidando com poucos dados, isso não chega a ser um problema. Contudo, caso essa base tenha um aumento substancial e o modelo precise ser retreinado, então isso pode vir a ser um tópico de discussão no futuro.\n",
    "De toda forma, é bom ter um entendimento básico de como nosso modelo funciona na prática. No nosso caso, imagine que temos dois conjuntos de pontos: Alunos que precisam de Intervenção e Alunos que não precisam. Tais pontos estão distribuidos no espaço de alguma forma e para cada um deles, nós temos um conjunto de atributos relacionado (Sexo, idade, Profissão do Pai, etc). Cada atributo tem uma influência sobre a posição dos pontos no espaço. Simplificadamente falando, o SVM procura encontrar a melhor \"linha\" que separa nossos dados. Tal \"ĺinha\" é conhecida como hiperplano. A fim de encontrar essa \"linha\", o SVM pode fazer o mapeamento dos nossos pontos, quando necessário, para um espaço de maior dimensão de forma que os pontos possam ser melhor separados. Em outras palavras, o SVM apenas precisa descobrir a melhor linha/hiperplano que classifica nossos dados. Feito isso, ele usa tal linha pra classificar novas instâncias observando em qual lado do hiperplano as mesmas se encontram. Abaixo segue uma ilustração para melhor entendimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Imagine que temos o problema de classificar um ponto como azul ou vermelho e, para isso, nós temos o conjunto de dados abaixo. Uma estratégia seria encontrar uma forma de separar tal conjunto de dados, onde de um lado temos apenas azuis e do outro vermelho. Assim sendo, quando chegar um novo ponto para classificar, só precisamos observar em qual lado ele ficou. Podemos fazer uma analogia com o problema original e supor que os pontos azuis e vermelhos representam alunos que não precisam de intervenção e alunos que precisam, respectivamente.</p>\n",
    "<img src=\"svm1.png\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Uma <i>linha</i> aparenta ser uma boa maneira de fazer a separação. Como dito anteriormente, o termo correto para essa linha é <b>hiperplano</b>. A figura abaixo apresenta três diferentes hiperplanos que separam os dados, porém o amarelo é o melhor, pois o __SVM__ procura encontrar o hiperplano que maximiza a distância entre as duas classes de pontos. Perceba que o amarelo é o único que apresenta uma distância segura entre os dois tipos de pontos. Ao passo que, o lilás está bastante próximo do vermelho, e o rosa do azul, o que pode causar erros na classificação.</p>\n",
    "<img src=\"svm2.png\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Abaixo vemos o melhor hiperplano dividindo nossos dados. Todo o processo que nos levou a encontrar o hiperplano amarelo é a fase de treinamento de modelo como foi mencionado anteriormente. De agora em diante, nós podemos usar tal hiperplano pra classificar um ponto desconhecido baseado em qual lado do hiperplano o mesmo se encontra. Caso nós tenhamos um diferente conjunto de pontos e que já estejam classificados como vermelho ou azul, então nós podemos usá-los  para saber o quão bom é nosso hiperplano, bastando apenas comparar a classificação real do ponto com aquela que o hiperplano diz (Fase de teste). Quanto mais as duas classificações sejam iguais, mais segurança nós temos que escolhemos um bom hiperplano e, consequentemente, um bom modelo para nosso problema. </p>\n",
    "<img src=\"svm3.png\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Calibrando o Modelo (_Tuning_)\n",
    "Calibre o modelo escolhido. Utilize busca em matriz (`GridSearchCV`) com, pelo menos, um parâmetro importante calibrado com, pelo menos, 3 valores diferentes. Você vai precisar utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você deve implementar o seguinte:\n",
    "- Importe [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Crie o dicionário de parâmetros que você deseja calibrar para o modelo escolhido.\n",
    " - Examplo: `parameters = {'parameter' : [list of values]}`.\n",
    "- Inicialize o classificador que você escolheu e armazene-o em `clf`.\n",
    "- Crie a função de pontuação F<sub>1</sub> utilizando `make_scorer` e armazene-o em `f1_scorer`.\n",
    " - Estabeleça o parâmetro `pos_label` para o valor correto!\n",
    "- Execute uma busca em matriz no classificador `clf` utilizando o `f1_scorer` como método de pontuação e armazene-o em `grid_obj`.\n",
    "- Treine o objeto de busca em matriz com os dados de treinamento (`X_train`, `y_train`) e armazene-o em `grid_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As previsões foram feitas em 0.0035 segundos.\n",
      "O modelo calibrado tem F1 de 0.8000 no conjunto de treinamento.\n",
      "As previsões foram feitas em 0.0012 segundos.\n",
      "O modelo calibrado tem F1 de 0.8125 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar\n",
    "parameters = {'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
    "              'C': [1, 5, 10]}\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "clf = svm.SVC()\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score, pos_label='yes')\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=f1_scorer)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetrosprint \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros:  {'kernel': 'sigmoid', 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "print \"Melhores parâmetros: \", grid_obj.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Pontuação F<sub>1</sub> Final\n",
    "*Qual é a pontuação F<sub>1</sub> do modelo final para treinamento e teste? Como ele se compara ao modelo que não foi calibrado?*\n",
    "\n",
    "O modelo final apresentou uma pontuação de _0.8000_ e _0.8125_ nos conjuntos de treino e teste respectivamente. Ele apresentou uma leve queda de performance quando comparado com o modelo não calibrado, já que esse conseguiu um F1 de _0.8596_ e _0.8344_ no treino e teste respectivamente. E considerando 300 pontos para treinar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você completou todas as implementações de código e respondeu todas as questões acima com êxito, você pode finalizar seu trabalho exportando o iPython Nothebook como um document HTML. Você pode fazer isso utilizando o menu acima e navegando para  \n",
    "**File -> Download as -> HTML (.html)**. Inclua a documentação final junto com o notebook para o envio do seu projeto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
