{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "##### Arthur Sena, 14/08/2018\n",
    "\n",
    "<center> <h1>Projeto Final - Relatório </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Introdução\n",
    "<div style=\"text-align: justify\"> O cérebro humano é uma das partes mais fascinantes do corpo humano. Ele é o núcleo que controla diversas das nossas ações diárias. Desde às mais complexas, como resolver uma derivada numa prova de cálculo I, até às mais simples, como reconhecer se uma foto contém ou não um cachorro. E é sobre essa ação de reconhecer uma determinada imagem, foto ou retrato que esse projeto se trata. Essa que parece ser uma tarefa simples para nós, seres humanos, não é tão fácil para um computador que apenas enxerga números binários.  </div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">Por esse motivo que, ao longo das últimas décadas, diversos algoritmos e técnicas foram desenvolvidos com o intuito de indentificar e reconhecer padrões em imagens. Assim sendo, esse relatório descreve o desenvolvimento de um modelo de aprendizagem de máquina que utiliza tais técnicas e é capaz de reconhecer imagens de três tipos diferentes de ambientes:</div>\n",
    "\n",
    "   - Urbano: Imagens relacionadas com ambientes de cidades, prédios, casas, etc.\n",
    "   - Natureza: Imagens relacionadas com ambientes de florestas, matas, jardins, etc.\n",
    "   - Praia/Litoral: Imagens realacionadas com praias, mares, areia, etc.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: justify\">É importante ressaltar que o foco desse projeto foi a utilização de algoritmos de <i>Deep Learning</i>, visto que estes apresentam os melhores resultados no campo de reconhecimento de imagem como um todo. Nas seções abaixos, é descrito todos os passos que envolveram o desenvolvimento do melhor modelo encontrado.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Dados\n",
    "<div style=\"text-align: justify\">O primeiro desafio encontrado foi a necessidade de construção de uma base de dados de imagens que contivesse os ambientes que estamos tentando reconhecer. Cada um desses ambientes possue uma determinada peculiaridade, padrão e caracteristica que deve estar presentes na nossa base, pois assim o nosso modelo irá aprendê-lo. Dessa forma, resolvemos utilizar a rede social de fotos mais famosa do mundo conhecida como _Instagram_ como a fonte da nossa base. Para isso, foi criado um _script_ em python que acessou os seguintes perfis :</div>\n",
    "   \n",
    "   * <a href=\"https://www.instagram.com/big.cities/\">Perfil Urbano</a>\n",
    "   * <a href=\"https://www.instagram.com/beaches_n_resorts/\">Perfil de Praias e Litoral</a>\n",
    "   * <a href=\"https://www.instagram.com/forest/\">Perfil de Natureza e floretas</a>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "O nosso script acessou e coletou cada uma das fotos dos links acima, resultando numa base com <b>945</b> imagens, sendo <b>259</b> fotos de cidades, <b>292</b> de florestas e <b>394</b> de praias. Todas essas imagens estão coloridas e apresentam um tamanho original de 640x640. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Métricas\n",
    "<div style=\"text-align: justify\">\n",
    "A fim de avaliar nossos modelos, devemos sempre utilizar algumas métricas de performance. No nosso contexto, queremos classificar as fotos em três diferentes classes, dessa forma decidimos usar a Precisão e Recall por label, juntamente com a Acurácia na avaliação. Segue abaixo as métricas:</div>\n",
    "\n",
    "- Pra cada uma das classes (c), será calculada a precisão e recall seguindo as fórmulas abaixo:\n",
    "\n",
    "\\begin{equation*}\n",
    "    Precision(c) = \\frac{TP(c)}{TP(c)+FP(c)}\n",
    "\\end{equation*}    \n",
    "\n",
    "\\begin{equation*}\n",
    "    Recall(c) = \\frac{TP(c)}{TP(c)+FN(c)}\n",
    "\\end{equation*}  \n",
    "\n",
    "- E a acuŕacia também será considerada na avaliação:\n",
    "\n",
    "\\begin{equation*}\n",
    "    Acc = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "\\end{equation*}  \n",
    "\n",
    "### 4) Modelo de Benchmark\n",
    "<div style=\"text-align: justify\">\n",
    "O algoritmo conhecido como [KNN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) foi escolhido como o modelo de benchmark. A ideia desse algoritmo é utilizar dos \"K\" vizinhos mais próximos de um determinado dado a fim de classificá-lo.</div>\n",
    "\n",
    "#### 4.1) Pré-processamento\n",
    "<div style=\"text-align: justify\">Antes de aplicar KNN nos dados, algum pré-processamento foi necessário, a fim de transformar as imagens em um formato que possa ser aceito pelo algoritmo. Contudo, é bom lembrar que estamos tentando criar um modelo que possa identificar três diferentes padrões de imagens, ou seja, precisamos processar elas, de forma que realce as diferenças de caracteristicas, o que por sua vez, facilita o aprendizado do modelo. Sabemos que uma imagem pode ser representada como uma matrix de pixels que variam de 0 até 255. Todas as nossas imagens são coloridas e seguem o padrão RGB (Red, Green e Blue), ou seja,  cada imagem é composta por, na verdade, três matrizes de pixels, no qual cada uma remete à uma das três cores. Com isso em mente, uma boa estratégia é usar um histograma de cores de cada imagem como features para o modelo, visto que cada um dos ambientes apresenta uma distribuição particular. </div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\"> <b>Observação</b>: O histograma original de cada imagem se tornou dificil de processar utilizando o laptop que se encontra à disposição, pois o mesmo acabava criando um demasiado espaço de features. Por consequência, foi necessário diminuir o tamanho do histograma à partir do aumento dos <i>bins</i> dos mesmos. As imagens abaixo representam a distribuição de cores de cada imagem após tal processamento. Note que cada cor representa uma das cores RGB. Além disso, todas as imagens foram redimensionadas para tamanho <b>32x32</b> logo antes da criação dos histogramas.</div>\n",
    "\n",
    "\n",
    "<img src=\"images/cities_histogram.png\"/>\n",
    "<center> <h3> Histograma de cores para imagens urbanas </h3></center>\n",
    "\n",
    "\n",
    "<img src=\"images/beaches_histogram.png\"/>\n",
    "<center> <h3> Histograma de cores para imagens de praias </h3></center>\n",
    "\n",
    "\n",
    "<img src=\"images/forest_histogram.png\"/>\n",
    "<center> <h3> Histograma de cores para imagens de florestas </h3></center>\n",
    "\n",
    "<div style=\"text-align: justify\"> Observando os histogramas acima, vemos claramente que as distribuições são, realmente, distinguíveis entre si. É perceptível que nas imagens relacionadas com florestas e cidades, a distribuição das cores ocorre de forma mais similar entre elas, ao passo que no contexto de praias, não é tão similar, visto que a distribuição do vermelho destoa bastante do verde e azul. </div>\n",
    "\n",
    "#### 4.2) Treinando o modelo de benchmark: KNN\n",
    "<div style=\"text-align: justify\">O treinamento do KNN usa como entrada a distribuição de cores de cada imagem. Sendo que, foi aplicado um algoritmo conhecido como _grid search_, a fim de encontrar a melhor quantidade de vizinhos a ser considerada quando classificar uma imagem. Além disso, 80% das imagens foram usadas como dados de treino e o resto como teste. O parâmetro *random_split*, também, foi utilizado para caso seja necessário replicar a separação de treino e teste, e, com isso, facilitar a comparação com outros modelos. Os resultados das métricas podem ser visualizados abaixo:</div>\n",
    "\n",
    "- Quantidade de imagens usadas no treino: **756**\n",
    "- Quantidade de imagens usadas no teste:  **189**\n",
    "\n",
    "- Configuração do melhor modelo\n",
    "\n",
    "```python\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
    "           weights='uniform')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultados da aplicação do modelo nos dados de teste pode ser visto. Tais resultados serão usados como parâmetro para indicar se os outros modelos criados obtiveram ou não sucesso.\n",
    "<img src=\"images/benchmark_cm_test.png\"/>\n",
    "<img src=\"images/knn_precision_label.png\"/>\n",
    "<img src=\"images/knn_recall_label.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Deep Learning\n",
    "<div style=\"text-align: justify\"><i>Deep learning</i> é um conjunto de técnicas e algoritmos que envolve o uso de redes neurais profundas, ou seja, com muitas camadas. Esses tipos de redes neurais ganharam bastante atenção após os seus ótimos desempenhos nos campos de reconhecimento de imagem e voz. Pensando nisso, foi desenvolvido e avaliado duas arquiteturas de modelos _deep learning_ nesse projeto. <i>Keras</i> foi o framework utilizado na construção de tais modelos.</div>\n",
    "\n",
    "#### 5.1) Pré-processamento\n",
    "<div style=\"text-align: justify\">Todas as imagens foram redimensionadas para o tamanho de <b>32x32</b> e os pixels foram colocados no intervalo de zero à um pela divisão dos mesmo por 255.</div>\n",
    "\n",
    "#### 5.2) Primeira arquitetura\n",
    "- A primeira arquitetura construída e avaliada contém três camadas _Denses_ com 500, 300 e 100 neurônios cada, seguida por uma camada _Flatten_ com 102400 neurônios e, por fim, a camada de softmax com 3 neurônios. Ademais, uma camada de _Dropout_ foi adicionada entre cada camada _Dense_ a fim de evitar _overfitting_. Tal arquitetura pode ser melhor sumarizada na imagem abaixo.\n",
    "<img src=\"images/dl_first_architecture.png\"/>\n",
    "\n",
    "- O primeiro experimento foi executado com 80 épocas e a curva do erro no teste e treino pode ser vista abaixo.\n",
    "<img src=\"images/first_architecture_loss_graph.png\"/>\n",
    "\n",
    "- Observando o gráfico acima, notamos que não precisamos usar tantas épocas, visto que o erro do teste para de descer por volta da época vinte e quatro. Por isso, resolvemos rodar novamente o experimento com vinte e quatro épocas apenas. Os resultados da aplicação do modelo nos dados de teste pode ser visto abaixo.\n",
    "\n",
    "<img src=\"images/dl_first_architecture_cm_test.png\"/>\n",
    "\n",
    "<img src=\"images/dl_first_architecture_precision_label.png\"/>\n",
    "\n",
    "<img src=\"images/dl_first_architecture_recall_label.png\"/>\n",
    "\n",
    "Os resultados acima já indicam uma boa evolução em relação ao modelo de benchmark. Lembrando, que a divisão de dados de treino e teste foi mantida, pois dessa forma, conseguimos fazer uma comparação justa entre os modelos. \n",
    "\n",
    "#### 5.3) Segunda arquitetura\n",
    "A segunda arquitetura foi contruída em cima dos conceitos de _Convolutional Neural Networks_ e _Max Pooling_. Abaixo segue uma explicação sobre tais conceitos e o porquê eles foram escolhidos.\n",
    "    \n",
    "- **Camadas convolucionais**: Tais camadas são muito úteis quando queremos discriminar melhor os padrões que estamos tentando ensinar à nossa rede neural. Elas funcionam por meio da convolução/deslizamento de um filtro sobre a imagem original. Dessa forma, esse filtro é capaz de identificar diferentes padrões em diferentes partes da imagem. Esse tipo de camada, diferentemente das camadas _Denses_, é localmente conectada, ou seja, seus neurônios são conectados à um subconjunto de neurônios da camada anterior, o que diminui bastante a complexidade da rede.\n",
    "\n",
    "- **Camadas do tipo Pooling**: Tais camadas são, geralmente, aplicadas, logo após, uma camada de convolução. Elas funcionam de forma similar as camadas convolucionais, no qual, em ambas fazemos o deslizamento de um filtro. Nesse projeto, nós focamos em camadas do tipo _Max_, onde as mesmas selecionam o pixel de maior valor dentro da janela de filtro para que esse seja considerado o valor do nó. A vantagem dessa técnica é a redução de dimensionalidade causada pelo filtro que, consequentemente, gera uma redução do custo computacional de construção o modelo, visto que diminui a quantidade de parâmetros. Além disso, conseguimos aumentar as chances de evitar um possível _overfitting_, visto que temos menos parâmetros.\n",
    "    \n",
    "Redes neurais convolucionais vem apresentando excelentes resultados no campo de classificação de imagens, e por isso, decidimos aplicar tal técnica nesse projeto. A arquitetura sumarizada da rede pode ser vista abaixo:\n",
    "<img src=\"images/dl_second_architecture.png\"/>\n",
    "\n",
    "- Gráfico da curva do erro.\n",
    "<img src=\"images/second_architecture_loss_graph.png\"/>\n",
    "- O modelo escolhido foi treinado com 80 épocas, sendo que observando a curva do erro no gráfico acima, não sentimos necessidade de diminuir a quantidade de épocas. Os resultados da aplicação de tal modelo nos dados de teste pode ser visto logo abaixo.\n",
    "\n",
    "<img src=\"images/dl_second_architecture_cm_test.png\"/>\n",
    "\n",
    "<img src=\"images/dl_second_architecture_precision_label.png\"/>\n",
    "\n",
    "<img src=\"images/dl_second_architecture_recall_label.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Sumarização dos resultados\n",
    "Os resultados das métricas foram sumarizados na tabela abaixo:\n",
    "<img src=\"images/summarization_table.png\"/>\n",
    " \n",
    "*Obs: O valor das métricas de revocação e precisão foram calculadas a partir da média da precisão e revocação de cada classe.\n",
    "\n",
    "Fica evidente que os resultados da segunda arquitetura foram melhores do que da primeira, e substancialmente, melhores do que o nosso modelo de _benchmark_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Conclusão\n",
    "<div style=\"text-align: justify\">Nesse projeto, demonstramos ser possível utilizar uma arquitetura de <i>deep learning</i> para classificar imagens de três ambientes diferentes. Verificamos, também, que o uso de técnicas de convolução melhorou a performance do modelo, sendo tal arquitetura escolhida como a melhor. Ainda assim, acreditamos que o modelo ainda possa ser evoluido. Aumentar a base de imagens, que atualmente apresenta 945 fotos, seria uma boa alternativa, haja visto que técnicas de <i>deep learning</i> possuem melhores resultados quando aplicadas em grandes bases. Isso não foi aplicado nesse projeto devido à pouca capacidade computacional que tínhamos disponível.</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">Além disso, vale ressaltar que todo o fluxo de trabalho necessário para construção de um modelo de aprendizagem de máquina foi seguido. Começando desde o desenvolvimento da base de dados, passando pelo treinamento dos modelos e chegando na escolha do melhor. É interessante deixar grifado que um tempo significante foi despendido na obtenção da base de treino de imagens, no qual a mesma foi construída a partir de conhecimentos de programação e técnicas de <i>web crawler</i>. O que corrobora a ideia de que a área de ciência de dados e aprendizagem de máquina em geral é bastante multidisciplinar por, muitas vezes, exigir que o profissional da área apresente conhecimentos estatisticos, matemáticos e de programção.  </div>\n",
    "\n",
    "### 8) Referências\n",
    "<a href=\"https://keras.io/\">Keras Documentação</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
